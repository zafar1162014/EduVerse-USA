{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EduVerse USA Chatbot â€” Intent Classification\n",
        "\n",
        "## NLP Pipeline Module 2\n",
        "\n",
        "This notebook classifies user queries into intent categories.\n",
        "\n",
        "### Intent Categories\n",
        "- **admissions**: University application queries\n",
        "- **sop**: Statement of Purpose guidance\n",
        "- **scholarships**: Funding and financial aid\n",
        "- **test_prep**: GRE, TOEFL, IELTS preparation\n",
        "\n",
        "### Approach\n",
        "TF-IDF features + Logistic Regression with confidence scoring."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install scikit-learn pandas matplotlib seaborn -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Setup complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = {\n",
        "    'text': [\n",
        "        # Admissions (12 samples)\n",
        "        \"What documents are required for MS admissions?\",\n",
        "        \"Application deadline for fall intake at Stanford\",\n",
        "        \"How many letters of recommendation do I need?\",\n",
        "        \"What GPA is required for top universities?\",\n",
        "        \"Requirements for PhD admission in computer science\",\n",
        "        \"How to apply for graduate school in America\",\n",
        "        \"What is the application process for US universities?\",\n",
        "        \"Transcript requirements for international students\",\n",
        "        \"When should I start my application for fall 2026?\",\n",
        "        \"Do I need work experience for MBA admission?\",\n",
        "        \"University application checklist for MS programs\",\n",
        "        \"Prerequisites for data science masters degree\",\n",
        "        \n",
        "        # SOP (12 samples)\n",
        "        \"How do I write a strong statement of purpose?\",\n",
        "        \"Can you review my SOP draft?\",\n",
        "        \"What should I include in my personal statement?\",\n",
        "        \"SOP tips for computer science programs\",\n",
        "        \"How long should my statement of purpose be?\",\n",
        "        \"Structure of a good SOP for MS applications\",\n",
        "        \"Common mistakes to avoid in SOP writing\",\n",
        "        \"How to show motivation in my personal statement\",\n",
        "        \"Should I mention my research experience in SOP?\",\n",
        "        \"How to write about career goals in SOP\",\n",
        "        \"Essay writing tips for graduate admissions\",\n",
        "        \"Personal statement examples for PhD applications\",\n",
        "        \n",
        "        # Scholarships (12 samples)\n",
        "        \"Are there scholarships for international students?\",\n",
        "        \"Fulbright scholarship application process\",\n",
        "        \"How to get funding for MS in USA?\",\n",
        "        \"Teaching assistantship opportunities\",\n",
        "        \"Research assistantship for PhD students\",\n",
        "        \"Merit-based scholarships at MIT\",\n",
        "        \"Financial aid options for graduate students\",\n",
        "        \"How to apply for university scholarships?\",\n",
        "        \"Tuition fee waiver for international students\",\n",
        "        \"External fellowship opportunities in the US\",\n",
        "        \"Assistantship vs scholarship difference\",\n",
        "        \"Need-based financial aid for masters programs\",\n",
        "        \n",
        "        # Test Prep (12 samples)\n",
        "        \"How to prepare for GRE in 2 months?\",\n",
        "        \"TOEFL vs IELTS - which is easier?\",\n",
        "        \"What GRE score do I need for top programs?\",\n",
        "        \"Best resources for TOEFL preparation\",\n",
        "        \"IELTS speaking test tips\",\n",
        "        \"GRE verbal section strategies\",\n",
        "        \"How to improve my TOEFL writing score?\",\n",
        "        \"GRE quantitative practice questions\",\n",
        "        \"Minimum IELTS score for US universities\",\n",
        "        \"GRE study plan for working professionals\",\n",
        "        \"TOEFL reading section time management\",\n",
        "        \"AWA essay tips for GRE\"\n",
        "    ],\n",
        "    'intent': (\n",
        "        ['admissions'] * 12 + \n",
        "        ['sop'] * 12 + \n",
        "        ['scholarships'] * 12 + \n",
        "        ['test_prep'] * 12\n",
        "    )\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(f\"Dataset: {len(df)} samples\")\n",
        "print(f\"\\nIntent distribution:\")\n",
        "print(df['intent'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Intent Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "colors = ['#3498db', '#e74c3c', '#2ecc71', '#9b59b6']\n",
        "df['intent'].value_counts().plot(kind='bar', color=colors)\n",
        "plt.title('Intent Distribution', fontsize=14)\n",
        "plt.xlabel('Intent')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. TF-IDF Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['text'], df['intent'], \n",
        "    test_size=0.25, \n",
        "    random_state=42,\n",
        "    stratify=df['intent']\n",
        ")\n",
        "\n",
        "# TF-IDF vectorizer\n",
        "tfidf = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=1000,\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "print(f\"Training samples: {X_train_tfidf.shape[0]}\")\n",
        "print(f\"Test samples: {X_test_tfidf.shape[0]}\")\n",
        "print(f\"Features: {X_train_tfidf.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=200),\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'Linear SVM': LinearSVC(),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(model, X_train_tfidf, y_train, cv=3)\n",
        "    \n",
        "    # Train and evaluate\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "    test_acc = accuracy_score(y_test, y_pred)\n",
        "    \n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'CV Mean': f\"{cv_scores.mean():.3f}\",\n",
        "        'CV Std': f\"{cv_scores.std():.3f}\",\n",
        "        'Test Acc': f\"{test_acc:.3f}\"\n",
        "    })\n",
        "    print(f\"{name}: CV={cv_scores.mean():.3f}, Test={test_acc:.3f}\")\n",
        "\n",
        "pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Final Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use Logistic Regression as final model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=model.classes_,\n",
        "            yticklabels=model.classes_)\n",
        "plt.title('Confusion Matrix', fontsize=14)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8. Confidence Scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_with_confidence(text):\n",
        "    \"\"\"Predict intent with confidence score.\"\"\"\n",
        "    vec = tfidf.transform([text])\n",
        "    probs = model.predict_proba(vec)[0]\n",
        "    pred = model.predict(vec)[0]\n",
        "    conf = max(probs)\n",
        "    return pred, conf, dict(zip(model.classes_, probs))\n",
        "\n",
        "# Test examples\n",
        "test_queries = [\n",
        "    \"How to prepare for GRE verbal section?\",\n",
        "    \"Scholarship opportunities at Harvard\",\n",
        "    \"Tips for writing a compelling SOP\",\n",
        "    \"What are the admission requirements for MIT?\"\n",
        "]\n",
        "\n",
        "print(\"Intent Predictions:\")\n",
        "print(\"=\" * 60)\n",
        "for query in test_queries:\n",
        "    intent, conf, probs = predict_with_confidence(query)\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    print(f\"Intent: {intent} (confidence: {conf:.1%})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 9. Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_names = tfidf.get_feature_names_out()\n",
        "\n",
        "for i, intent in enumerate(model.classes_):\n",
        "    coef = model.coef_[i]\n",
        "    top_idx = np.argsort(coef)[-5:][::-1]\n",
        "    top_features = [feature_names[j] for j in top_idx]\n",
        "    print(f\"\\n{intent}: {', '.join(top_features)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 10. Summary\n",
        "\n",
        "### Model Performance\n",
        "- **Logistic Regression** provides good accuracy with probability estimates\n",
        "- **TF-IDF bigrams** capture discriminative phrases\n",
        "\n",
        "### Key Takeaways\n",
        "1. Confidence scores help identify ambiguous queries\n",
        "2. Feature analysis reveals key terms for each intent\n",
        "3. Balanced dataset ensures fair classification across intents"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}