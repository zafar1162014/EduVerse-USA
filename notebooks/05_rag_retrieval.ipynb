{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EduVerse USA Chatbot — Retrieval-Augmented Generation\n",
        "\n",
        "## NLP Pipeline Module 5\n",
        "\n",
        "This notebook demonstrates RAG for grounding responses in factual knowledge.\n",
        "\n",
        "### Pipeline\n",
        "1. Build knowledge base with structured documents\n",
        "2. Generate semantic embeddings\n",
        "3. Index for efficient similarity search\n",
        "4. Retrieve relevant documents for queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install sentence-transformers faiss-cpu pandas numpy matplotlib -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "\n",
        "print(\"Loading embedding model...\")\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Setup complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Knowledge Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Document:\n",
        "    doc_id: str\n",
        "    title: str\n",
        "    content: str\n",
        "    category: str\n",
        "\n",
        "knowledge_base = [\n",
        "    Document(\"adm_001\", \"Graduate Admission Requirements\",\n",
        "             \"U.S. graduate programs require: transcripts, test scores (GRE/GMAT), SOP, letters of recommendation, resume. International students need TOEFL/IELTS.\",\n",
        "             \"admissions\"),\n",
        "    Document(\"adm_002\", \"Application Deadlines\",\n",
        "             \"Most universities have Fall deadlines in December-January. Early decision in October-November. Spring deadlines in September-October.\",\n",
        "             \"admissions\"),\n",
        "    Document(\"sop_001\", \"Statement of Purpose Structure\",\n",
        "             \"A strong SOP includes: motivation, academic background, research experience, program fit, career goals. Length: 500-1000 words.\",\n",
        "             \"sop\"),\n",
        "    Document(\"sop_002\", \"SOP Writing Tips\",\n",
        "             \"Be specific about why this program. Use concrete examples. Research faculty. Connect experience to goals. Proofread carefully.\",\n",
        "             \"sop\"),\n",
        "    Document(\"sch_001\", \"Scholarship Types\",\n",
        "             \"Options: merit scholarships, need-based aid, TA/RA assistantships, fellowships (Fulbright), tuition waivers.\",\n",
        "             \"scholarships\"),\n",
        "    Document(\"sch_002\", \"Fulbright Program\",\n",
        "             \"Fulbright covers tuition, living expenses, travel. Apply February, deadline October. Requires strong academics and leadership.\",\n",
        "             \"scholarships\"),\n",
        "    Document(\"test_001\", \"GRE Overview\",\n",
        "             \"GRE: Verbal (130-170), Quantitative (130-170), Analytical Writing (0-6). Total 260-340. Target 315+ for MS, 320+ for PhD.\",\n",
        "             \"test_prep\"),\n",
        "    Document(\"test_002\", \"TOEFL Requirements\",\n",
        "             \"TOEFL iBT: 0-120 total. Most universities require 80-100. Top programs expect 100+. Valid 2 years.\",\n",
        "             \"test_prep\"),\n",
        "    Document(\"test_003\", \"IELTS vs TOEFL\",\n",
        "             \"IELTS: 1-9 band. Typical requirement 6.5-7.0 (equivalent to TOEFL 90-100). IELTS has live speaking interview.\",\n",
        "             \"test_prep\")\n",
        "]\n",
        "\n",
        "print(f\"Knowledge base: {len(knowledge_base)} documents\")\n",
        "print(f\"Categories: {set(d.category for d in knowledge_base)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Generate Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "texts = [f\"{doc.title}. {doc.content}\" for doc in knowledge_base]\n",
        "\n",
        "print(\"Generating embeddings...\")\n",
        "embeddings = model.encode(texts, show_progress_bar=True)\n",
        "\n",
        "print(f\"Shape: {embeddings.shape}\")\n",
        "print(f\"Dimension: {embeddings.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. FAISS Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(dimension)\n",
        "\n",
        "faiss.normalize_L2(embeddings)\n",
        "index.add(embeddings.astype('float32'))\n",
        "\n",
        "print(f\"FAISS index: {index.ntotal} vectors\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Retrieval Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve(query: str, top_k: int = 3) -> List[Tuple[Document, float]]:\n",
        "    \"\"\"Retrieve most relevant documents.\"\"\"\n",
        "    query_emb = model.encode([query])\n",
        "    faiss.normalize_L2(query_emb)\n",
        "    \n",
        "    scores, indices = index.search(query_emb.astype('float32'), top_k)\n",
        "    \n",
        "    results = []\n",
        "    for idx, score in zip(indices[0], scores[0]):\n",
        "        results.append((knowledge_base[idx], float(score)))\n",
        "    return results\n",
        "\n",
        "# Test\n",
        "query = \"How do I write a good statement of purpose?\"\n",
        "results = retrieve(query)\n",
        "\n",
        "print(f\"Query: {query}\")\n",
        "print(\"\\nTop Results:\")\n",
        "for doc, score in results:\n",
        "    print(f\"  [{score:.3f}] {doc.title}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Test Multiple Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_queries = [\n",
        "    \"What GRE score do I need?\",\n",
        "    \"Scholarships for international students\",\n",
        "    \"TOEFL vs IELTS which is better?\",\n",
        "    \"Application deadline for fall\"\n",
        "]\n",
        "\n",
        "print(\"Retrieval Results\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for query in test_queries:\n",
        "    results = retrieve(query, top_k=2)\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    for doc, score in results:\n",
        "        print(f\"  → [{doc.category}] {doc.title} ({score:.3f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Embedding Space Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=5)\n",
        "emb_2d = tsne.fit_transform(embeddings)\n",
        "\n",
        "category_colors = {\n",
        "    'admissions': '#3498db',\n",
        "    'sop': '#e74c3c',\n",
        "    'scholarships': '#2ecc71',\n",
        "    'test_prep': '#9b59b6'\n",
        "}\n",
        "colors = [category_colors[doc.category] for doc in knowledge_base]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(emb_2d[:, 0], emb_2d[:, 1], c=colors, s=200)\n",
        "\n",
        "for i, doc in enumerate(knowledge_base):\n",
        "    plt.annotate(doc.doc_id, (emb_2d[i, 0], emb_2d[i, 1]), fontsize=8)\n",
        "\n",
        "for cat, color in category_colors.items():\n",
        "    plt.scatter([], [], c=color, s=100, label=cat)\n",
        "plt.legend()\n",
        "\n",
        "plt.title('Document Embeddings (t-SNE)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8. RAG Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rag_response(query: str, top_k: int = 2) -> dict:\n",
        "    \"\"\"Complete RAG pipeline.\"\"\"\n",
        "    retrieved = retrieve(query, top_k)\n",
        "    \n",
        "    context = []\n",
        "    sources = []\n",
        "    \n",
        "    for doc, score in retrieved:\n",
        "        if score > 0.3:  # Relevance threshold\n",
        "            context.append(doc.content)\n",
        "            sources.append({'id': doc.doc_id, 'title': doc.title, 'score': round(score, 3)})\n",
        "    \n",
        "    return {\n",
        "        'query': query,\n",
        "        'context': ' '.join(context),\n",
        "        'sources': sources\n",
        "    }\n",
        "\n",
        "result = rag_response(\"What are graduate admission requirements?\")\n",
        "\n",
        "print(\"RAG Output\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Query: {result['query']}\")\n",
        "print(f\"\\nSources:\")\n",
        "for src in result['sources']:\n",
        "    print(f\"  - {src['title']} ({src['score']})\")\n",
        "print(f\"\\nContext: {result['context'][:200]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 9. Summary\n",
        "\n",
        "### RAG Components\n",
        "- **Knowledge base** with structured documents\n",
        "- **Semantic embeddings** using Sentence Transformers\n",
        "- **FAISS indexing** for efficient search\n",
        "- **Context building** for response grounding\n",
        "\n",
        "### Key Takeaways\n",
        "1. Semantic search finds relevant content without exact matches\n",
        "2. Embedding visualization shows category clustering\n",
        "3. Relevance thresholds filter low-quality matches\n",
        "4. Source attribution enables fact verification"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}