{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EduVerse USA Chatbot — Response Generation\n",
    "\n",
    "## NLP Pipeline Module 6\n",
    "\n",
    "This notebook demonstrates fact-grounded response generation with hallucination prevention.\n",
    "\n",
    "### Key Principles\n",
    "- Ground responses in retrieved passages\n",
    "- Use intent and entities for personalization\n",
    "- Prevent hallucination with guardrails\n",
    "- Recommend official source verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional\n",
    "import textwrap\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Input Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example input created\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class GenerationInput:\n",
    "    \"\"\"Inputs for response generation.\"\"\"\n",
    "    user_query: str\n",
    "    intent: str\n",
    "    confidence: float\n",
    "    entities: Dict\n",
    "    passages: List[str]\n",
    "    context: Optional[str] = None\n",
    "\n",
    "example = GenerationInput(\n",
    "    user_query=\"What GRE score do I need for Stanford CS?\",\n",
    "    intent=\"test_prep\",\n",
    "    confidence=0.92,\n",
    "    entities={'universities': ['Stanford'], 'tests': ['GRE']},\n",
    "    passages=[\"GRE: Verbal (130-170), Quant (130-170). Target 315+ for MS, 320+ for PhD.\"],\n",
    "    context=\"Universities: Stanford | Programs: CS\"\n",
    ")\n",
    "\n",
    "print(\"Example input created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Hallucination Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardrails:\n",
      "  1. Only state facts from retrieved passages.\n",
      "  2. For specific deadlines/fees, recommend checking official sources.\n",
      "  3. If information is missing, ask clarifying questions.\n",
      "  4. Use hedging language ('typically', 'generally') for uncertainty.\n",
      "  5. Never invent statistics or specific numbers.\n"
     ]
    }
   ],
   "source": [
    "GUARDRAILS = [\n",
    "    \"Only state facts from retrieved passages.\",\n",
    "    \"For specific deadlines/fees, recommend checking official sources.\",\n",
    "    \"If information is missing, ask clarifying questions.\",\n",
    "    \"Use hedging language ('typically', 'generally') for uncertainty.\",\n",
    "    \"Never invent statistics or specific numbers.\"\n",
    "]\n",
    "\n",
    "print(\"Guardrails:\")\n",
    "for i, rule in enumerate(GUARDRAILS, 1):\n",
    "    print(f\"  {i}. {rule}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Response Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Templates defined for 4 intents\n"
     ]
    }
   ],
   "source": [
    "TEMPLATES = {\n",
    "    'admissions': {\n",
    "        'greeting': \"Here's what you need to know about admissions\",\n",
    "        'prompt': \"Would you like more details about any requirement?\"\n",
    "    },\n",
    "    'sop': {\n",
    "        'greeting': \"Let me help with your Statement of Purpose\",\n",
    "        'prompt': \"Would you like me to review your SOP draft?\"\n",
    "    },\n",
    "    'scholarships': {\n",
    "        'greeting': \"Here are funding options to consider\",\n",
    "        'prompt': \"Want details about specific scholarships?\"\n",
    "    },\n",
    "    'test_prep': {\n",
    "        'greeting': \"Here's guidance for test preparation\",\n",
    "        'prompt': \"Would you like a study plan?\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Templates defined for {len(TEMPLATES)} intents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Response Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(inp: GenerationInput) -> str:\n",
    "    \"\"\"Generate grounded response.\"\"\"\n",
    "    parts = []\n",
    "    template = TEMPLATES.get(inp.intent, {})\n",
    "    \n",
    "    # Greeting with entities\n",
    "    greeting = template.get('greeting', 'Here is the information')\n",
    "    if inp.entities.get('universities'):\n",
    "        greeting += f\" for {', '.join(inp.entities['universities'])}\"\n",
    "    parts.append(greeting + \":\")\n",
    "    parts.append(\"\")\n",
    "    \n",
    "    # Retrieved content\n",
    "    if inp.passages:\n",
    "        parts.append(\"**Key Information:**\")\n",
    "        for passage in inp.passages[:2]:\n",
    "            parts.append(textwrap.fill(passage, width=70))\n",
    "        parts.append(\"\")\n",
    "    \n",
    "    # Intent-specific guidance\n",
    "    if inp.intent == 'test_prep' and 'GRE' in inp.entities.get('tests', []):\n",
    "        parts.append(\"**Recommendations:**\")\n",
    "        parts.append(\"• For competitive CS programs, aim for GRE 320+\")\n",
    "        parts.append(\"• Focus on quantitative section for STEM\")\n",
    "        parts.append(\"\")\n",
    "    \n",
    "    # Low confidence clarification\n",
    "    if inp.confidence < 0.7:\n",
    "        parts.append(f\"*{template.get('prompt', 'Can you clarify?')}*\")\n",
    "    else:\n",
    "        parts.append(template.get('prompt', ''))\n",
    "    \n",
    "    # Verification reminder\n",
    "    parts.append(\"\")\n",
    "    parts.append(\"*Always verify official deadlines on university websites.*\")\n",
    "    \n",
    "    return \"\\n\".join(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Test Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response:\n",
      "============================================================\n",
      "Here's guidance for test preparation for Stanford:\n",
      "\n",
      "**Key Information:**\n",
      "GRE: Verbal (130-170), Quant (130-170). Target 315+ for MS, 320+ for\n",
      "PhD.\n",
      "\n",
      "**Recommendations:**\n",
      "• For competitive CS programs, aim for GRE 320+\n",
      "• Focus on quantitative section for STEM\n",
      "\n",
      "Would you like a study plan?\n",
      "\n",
      "*Always verify official deadlines on university websites.*\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(example)\n",
    "\n",
    "print(\"Generated Response:\")\n",
    "print(\"=\" * 60)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Multiple Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Test 1: How do I write a good SOP?\n",
      "Intent: sop (95%)\n",
      "============================================================\n",
      "Let me help with your Statement of Purpose:\n",
      "\n",
      "**Key Information:**\n",
      "A strong SOP includes: motivation, academic background, experience,\n",
      "program fit, career goals.\n",
      "\n",
      "Would you like me to review your SOP draft?\n",
      "\n",
      "*Always verify official deadlines on university websites.*\n",
      "\n",
      "============================================================\n",
      "Test 2: Scholarships at MIT?\n",
      "Intent: scholarships (88%)\n",
      "============================================================\n",
      "Here are funding options to consider for MIT:\n",
      "\n",
      "**Key Information:**\n",
      "Options: merit scholarships, TA/RA assistantships, fellowships,\n",
      "tuition waivers.\n",
      "\n",
      "Want details about specific scholarships?\n",
      "\n",
      "*Always verify official deadlines on university websites.*\n",
      "\n",
      "============================================================\n",
      "Test 3: What do I need to apply?\n",
      "Intent: admissions (65%)\n",
      "============================================================\n",
      "Here's what you need to know about admissions:\n",
      "\n",
      "**Key Information:**\n",
      "Requirements: transcripts, test scores, SOP, LORs, resume.\n",
      "\n",
      "*Would you like more details about any requirement?*\n",
      "\n",
      "*Always verify official deadlines on university websites.*\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "    GenerationInput(\n",
    "        user_query=\"How do I write a good SOP?\",\n",
    "        intent=\"sop\",\n",
    "        confidence=0.95,\n",
    "        entities={'programs': ['MS in CS']},\n",
    "        passages=[\"A strong SOP includes: motivation, academic background, experience, program fit, career goals.\"]\n",
    "    ),\n",
    "    GenerationInput(\n",
    "        user_query=\"Scholarships at MIT?\",\n",
    "        intent=\"scholarships\",\n",
    "        confidence=0.88,\n",
    "        entities={'universities': ['MIT']},\n",
    "        passages=[\"Options: merit scholarships, TA/RA assistantships, fellowships, tuition waivers.\"]\n",
    "    ),\n",
    "    GenerationInput(\n",
    "        user_query=\"What do I need to apply?\",\n",
    "        intent=\"admissions\",\n",
    "        confidence=0.65,  # Low confidence\n",
    "        entities={},\n",
    "        passages=[\"Requirements: transcripts, test scores, SOP, LORs, resume.\"]\n",
    "    )\n",
    "]\n",
    "\n",
    "for i, test in enumerate(test_cases, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Test {i}: {test.user_query}\")\n",
    "    print(f\"Intent: {test.intent} ({test.confidence:.0%})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(generate_response(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality Metrics:\n",
      "  grounded: ✓\n",
      "  entity_used: ✓\n",
      "  has_verification: ✓\n",
      "  word_count: ✓\n"
     ]
    }
   ],
   "source": [
    "def evaluate_response(response: str, inp: GenerationInput) -> Dict:\n",
    "    \"\"\"Evaluate response quality.\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Grounding check\n",
    "    metrics['grounded'] = any(\n",
    "        p[:30].lower() in response.lower() for p in inp.passages\n",
    "    ) if inp.passages else False\n",
    "    \n",
    "    # Entity mention\n",
    "    entity_mentioned = False\n",
    "    for vals in inp.entities.values():\n",
    "        for v in vals:\n",
    "            if v.lower() in response.lower():\n",
    "                entity_mentioned = True\n",
    "    metrics['entity_used'] = entity_mentioned\n",
    "    \n",
    "    # Verification reminder\n",
    "    metrics['has_verification'] = 'verify' in response.lower()\n",
    "    \n",
    "    # Length\n",
    "    metrics['word_count'] = len(response.split())\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "metrics = evaluate_response(response, example)\n",
    "\n",
    "print(\"Quality Metrics:\")\n",
    "for key, val in metrics.items():\n",
    "    status = \"✓\" if val else \"✗\" if isinstance(val, bool) else val\n",
    "    print(f\"  {key}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Summary\n",
    "\n",
    "### Response Generation Features\n",
    "- **Grounded generation** using retrieved passages\n",
    "- **Intent-aware templates** for structure\n",
    "- **Entity personalization** based on context\n",
    "- **Hallucination prevention** with verification reminders\n",
    "\n",
    "### Key Takeaways\n",
    "1. Template + retrieval = consistent, informative responses\n",
    "2. Confidence thresholds trigger clarification\n",
    "3. Quality metrics help evaluate responses\n",
    "4. Verification reminders prevent misinformation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
